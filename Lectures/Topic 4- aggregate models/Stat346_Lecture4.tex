\documentclass[compress,mathserif]{beamer}
\usepackage{amsmath, amssymb, amsfonts, amsxtra}
\usepackage{hyperref}

\mode<presentation> {
  \usetheme{default}
  \useoutertheme{infolines}
  \setbeamercovered{transparent}
}

\title[Aggregate Loss Models]{Introduction to Aggregate Loss Models}
\author{Chapter 9}
\institute[Stat 346]{Stat 346 - Short-term Actuarial Math}
\date[BYU]{}
\subject{Stat 346}

\begin{document}

\begin{frame}
 \titlepage
\end{frame}

% Introduction to Aggregate Loss Random Variable S
\begin{frame}
\frametitle{Introduction to Aggregate Loss Random Variable \( S \)}
\begin{itemize}
    \item Definition: Aggregate Loss Random Variable \( S = X_1 + X_2 + \cdots + X_n \)
    \item Represents the total loss over \( n \) policies or events. For now we assume that $n$ is fixed. 
    \item Finding the distribution of \( S \) is key in actuarial science.
\end{itemize}
\end{frame}

% Known Distributions of Sums of Random Variables
\begin{frame}
\frametitle{Known Distributions of Sums of Random Variables}
Common cases where the sum's distribution is known:
\begin{itemize}
    \item Normal distribution: If \( X_i \sim N(\mu, \sigma) \), then \( \sum X_i \sim N(n\mu, \sqrt{n}\sigma) \).
    \item Gamma distribution: If \( X_i \sim \text{Gamma}(\alpha, \beta) \), then \( \sum X_i \sim \text{Gamma}(n\alpha, \beta) \).
    \item Poisson distribution: If \( X_i \sim \text{Poisson}(\lambda) \), then \( \sum X_i \sim \text{Poisson}(n\lambda) \).
    \item Geometric distribution: If \( X_i \sim \text{Geometric}(\beta) \), then \( \sum X_i \sim \text{Negative Binomial}(r, \beta) \).
\end{itemize}
\end{frame}

% Mathematical Properties of Moment Generating Functions
\begin{frame}
\frametitle{Review of Moment Generating Functions (MGFs)}
\begin{itemize}
    \item MGF of a random variable \( X \): \( M_X(t) = E[e^{tX}] \).
    \item \textbf{Finding Moments}: The \( k \)-th moment is given by \( E[X^k] = M_X^{(k)}(0) \), where \( M_X^{(k)}(t) \) is the \( k \)-th derivative of \( M_X(t) \).
    \item \textbf{Central Moments}: For central moments, use \( E[(X - E[X])^k] \). For example, the variance (second central moment) is \( M_X^{(2)}(0) - [M_X^{(1)}(0)]^2 \).
    \item More commonly you. can find the $k$-th central mooment as the $k$-th derivative of the log of the moment. generating function at 0, $E[(X-\mu)^k] = \frac{d^k}{dt^k} \log{(M_X(t))} \vert_{t = 0}$
    \item Useful as a review of these properties for understanding how MGFs are applied in practice.
\end{itemize}
\end{frame}

% Using MGFs to Find Sums of Distributions
\begin{frame}
\frametitle{Using MGFs to Find Sums of Distributions}
\begin{itemize}
    \item MGFs greatly simplify finding the distribution of sums.
    \item The MGF of a sum of independent random variables is the product of their individual MGFs.
    \item If $M_{X_i}(t)$ is the moment generating function for $X_i$ then the. moment generating function of $S = X_1 + X_2 + ... + X_n$ is \[M_S(t) = \prod_{i=1}^n M_{X_i}(t) = M_X(t)^n\]
    \item This property enables us to determine the distribution type of the sum.
\end{itemize}
\end{frame}


% Proof: Sum of Exponentials is a Gamma Distribution
\begin{frame}
\frametitle{Proof: Sum of Exponentials is a Gamma Distribution}
\begin{itemize}
    \item Let \( X_i \) be Exponential with scale parameter \(\theta\) (or rate \(\lambda = 1/\theta\)).
    \item MGF of \( X_i \): \( M_{X_i}(t) = \frac{1}{1 - \theta t} \), for \( t < 1/\theta \).
    \item For the sum \( S = X_1 + \cdots + X_n \):
          \[ M_S(t) = \left(\frac{1}{1 - \theta t}\right)^n \]
    \item This MGF corresponds to a Gamma distribution with shape parameter \(\alpha = n\) and scale parameter \(\theta\).
    \item Hence, the sum of \( n \) independent Exponential variables each with scale \(\theta\) is a Gamma(\(n, \theta\)) distribution.
\end{itemize}
\end{frame}


% Convolution Method for n = 2
\begin{frame}
\frametitle{Convolution Method for \( n = 2 \)}
\begin{itemize}
    \item When \( n = 2 \), the distribution of \( S = X_1 + X_2 \) can be found by convolution.
    \item For continuous variables: \( f_S(s) = \int f_{X_1}(s - x) f_{X_2}(x) dx \)
    \item For discrete variables: \( p_S(s) = \sum p_{X_1}(s - x) p_{X_2}(x) \)
\end{itemize}
\end{frame}

% Creating Probability Distribution for S = X_1 + X_2
\begin{frame}
\frametitle{Creating Probability Distribution for \( S = X_1 + X_2 \)}
Given \( X_i \) can be 100, 200, or 300 with probabilities 0.25, 0.5, and 0.25:
\begin{itemize}
    \item Possible sums of \( X_1 \) and \( X_2 \) are 100, 200, and 300.
    \item Probability distribution of \( S \):
    \begin{itemize}
        \item \( \text{Pr}(S = 100) = 0.25 \)
        \item \( \text{Pr}(S = 200) = 0.5 \)
        \item \( \text{Pr}(S = 300) = 0.25 \)
    \end{itemize}
    \item Specifically, \( \text{Pr}(S = 400) = 0.375 \).
    \item This demonstrates the method to calculate and plot the probability distribution of \( S \).
\end{itemize}
\end{frame}

% Full Probability Distribution of S = X_1 + X_2
\begin{frame}
\frametitle{Full Probability Distribution for \( S = X_1 + X_2 \)}
Given \( X_i \) can be 100, 200, or 300 with probabilities 0.25, 0.5, and 0.25, the full probability distribution of \( S \) is:
\begin{table}
\centering
\begin{tabular}{cc}
\hline
Sum (\( S \)) & Probability \\
\hline
200 & 0.0625 \\
300 & 0.25 \\
400 & 0.375 \\
500 & 0.25 \\
600 & 0.0625 \\
\hline
\end{tabular}
\end{table}
\end{frame}


% Using Software for Higher n
\begin{frame}
\frametitle{Using Software for Higher \( n \)}
\begin{itemize}
    \item For larger \( n \), manual calculation becomes impractical.
    \item Statistical software can automate the process.
\end{itemize}
\end{frame}


%
%\section{Objectives}
%\frame{\frametitle{Objectives}
%\begin{itemize}
%\item Individual risk model
%\smallskip
%\item Collective risk model
%\smallskip
%\item Computing the aggregate loss models
%\smallskip
%\item Approximate methods
%\smallskip
%\item Effect of policy modifications
%\smallskip
%\item Chapter 9 (sections 9.1 - 9.7; exclude 9.6.1 and examples 9.9 and 9.11)
%\smallskip
%\item Assignment: read section 9.7
%\end{itemize}
%}

\section{Individual risk model}
\frame{\frametitle{Individual risk model}
\begin{itemize}
\item Consider a portfolio of $n$ insurance policies.
\smallskip
\item Denote the loss, for a fixed period, for each policy $i$ by $X_i$, for $i=1,\ldots,n$.
\smallskip
\item Assume these lossses are independent and (possibly) identically distributed.
\smallskip
\item The aggregate loss, $S$, is defined by the sum of these losses:
\begin{equation*}
S = X_1 + X_2 + \cdots + X_n.
\end{equation*}
\item It is possible that  a policy does not incur a loss so that each $X_i$ has a mixed distribution with a probability mass at zero.
\end{itemize}
}

\subsection{Alternative representation}
\frame{\frametitle{Alternative representation}
\begin{itemize}
\item Assume that the losses are also identically distributed say as $X$. Then we can write $X$ as the product of a Bernoulli $I$ and a positive (continuous) random variable $Y$:
\begin{equation*}
X = IY
\end{equation*}
\item $I=1$ indicates there is a claim, otherwise $I=0$ means no claim. Let $\text{Pr}(I=1) = q$ and hence $\text{Pr}(X=0) = 1-q$.
\smallskip
\item In addition, assume $\text{E}(Y) = \mu_Y$ and $\text{Var}(Y) = \sigma^2_Y$.
\smallskip
\item Typically it is assumed that $I$ and $Y$ are independent so that
\begin{equation*}
\text{E}(X) = \text{E}(I) \text{E}(Y) = q \mu_Y
\end{equation*}
and
\begin{equation*}
\text{Var}(X) =  q(1-q) \mu^2_Y + q \sigma^2_Y.
\end{equation*}
\end{itemize}
}

\subsection{Mean and variance}
\frame{\frametitle{Mean and variance in the individual risk model}
\begin{itemize}
\item The mean of the aggregate loss can thus be written as
\begin{equation*}
\text{E}(S) = nq\mu_Y
\end{equation*}
and its variance is
\begin{equation*}
\text{Var}(S) =  nq(1-q) \mu^2_Y + nq \sigma^2_Y.
\end{equation*}
\item \textbf{Example:} Consider a portfolio on 1,000 insurance policies where each policy has a probability of a claim of 0.15. When a claim occurs, the amount of claim has a Pareto distribution with parameters $\alpha=3$ and $\theta=100$. Calculate the mean and variance of the aggregate loss.
\end{itemize}
}


\subsection{Approximation by CLT}
\frame{\frametitle{Approximating the individual risk model}
\begin{itemize}
\item For large $n$, according to the Central Limit Theorem, $S$ can be approximated with a Normal distribution.
\smallskip
\item Then, probabilities can be computed using Normal as follows:
\begin{eqnarray*}
\text{Pr}(S \leq s) &=& \text{Pr} \left[ \frac{S-\text{E}(S)}{\sqrt{\text{Var}(S)}} \leq \frac{S-\text{E}(S)}{\sqrt{\text{Var}(S)}} \right] \\
&\approx& \text{Pr} \left[Z \leq \frac{S-\text{E}(S)}{\sqrt{\text{Var}(S)}} \right] \\
&=& \Phi \left( \frac{S-\text{E}(S)}{\sqrt{\text{Var}(S)}} \right)
\end{eqnarray*}
\end{itemize}
}


\subsection{Illustrative examples}
\frame{\frametitle{Illustrative examples}
\begin{itemize}
\item \textbf{Example 1:} An insurable event has a 10\% probability of occurring and when it occurs, the amount of the loss is exactly 1,000. Market research has indicated that consumers will pay at most 115 for insuring this event. How many policies must a company sell in order to have a 95\% chance of making money (ignoring expenses)? Assume Normal approximation.
\smallskip
\end{itemize}
}
%
%\subsection{Exact distribution using convolution}
%\frame{\frametitle{Exact distribution of $S$ using convolution}
%\begin{itemize}
%\item Consider the case of $S=X_1+X_2$. The density of $S$ can be computed using convolution as:
%\begin{equation*}
%f^{*2}(s) = f_{S}(s) = \int_{0}^{s} f_1(s-y) f_2(y) dy = \int_{0}^{s} f_2(s-y) f_1(y) dy
%\end{equation*}
%\item To extend to $n$ dimension, do it recursively. Let $f^{*(n-1)}(s)$ be the $(n-1)$-th convolution so that
%\begin{eqnarray*}
%f^{*n}(s) = f_{S}(s) &=& \int_{0}^{s} f^{*(n-1)}(s-y) f_n(y) dy \\
%&=& \int_{0}^{s} f_n(s-y) f^{*(n-1)}(y) dy
%\end{eqnarray*}
%\end{itemize}
%}
%
%\subsection{Mixed random variable}
%\frame{\frametitle{The case of the mixed random variable}
%\begin{itemize}
%\item Often, $X_i$ has a probability mass at zero so that its density function is given by
%\begin{equation*}
%f_i(x) = \left\{
%\begin{array}{ll}
%q_i, & \text{for } x=0, \\
%(1-q_i) f_{Y}(x), & \text{for } x>0,
%\end{array}
%\right.
%\end{equation*}
%where $f_Y(\cdot)$ is a legitimate density function of a positive continuous random variable. Here, $q_i$ is interpreted as the probability that the loss is zero.
%\smallskip
%\item In this case, use the cumulative distribution function:
%\begin{equation*}
%F^{*2}(s) = F_{S}(s) = \int_{0}^{s} F_1(s-y) dF_2(y) = \int_{0}^{s} F_2(s-y) dF_1(y)
%\end{equation*}
%\item To extend to $n$ dimension, do it recursively.
%\end{itemize}
%}
%
%\subsection{The case of the Exponential}
%\frame{\frametitle{The case of the Exponential distribution}
%Consider the case where $X_i$ has the density function expressed as
%\begin{equation*}
%f_i(x) = \left\{
%\begin{array}{ll}
%0.10, & \text{for } x=0, \\
%0.90 f_{Y}(x), & \text{for } x>0,
%\end{array}
%\right.
%\end{equation*}
%where $Y$ is an Exponential with mean 1, for $i=1,2$. \\
%\smallskip
%Derive expressions for the density and distribution functions of the sum $S=X_1+X_2$.
%}

\subsection{Illustrative example}
\frame{\frametitle{ Example 2}
An insurer has a portfolio consisting of 25 one-year life insurance policies grouped as follows:
\begin{center}
\begin{tabular}{ccc}
\hline Insured amount $b_{k}$ &  & Number of policies $n_{k}$ \\
\hline\hline
1 &  & 10 \\
2 &  & 5 \\
3 &  & 10 \\ \hline
\end{tabular}
\end{center}

The probability of dying within one year is $q_{k}=0.01$ for each insured, and the policies are independent. \\
\smallskip
The insurer sets up an initial capital of \$1 to cover its future obligations. \\
\smallskip
Using Normal approximation, calculate the probability that the insurer will be able to meet its financial obligation.
}

\section{Collective risk model}
\frame{\frametitle{Collective risk model}
\begin{itemize}
\item Let $X_i$ be the claim payment made for the $i$th policyholder and let $N$ be the random number of claims. The
insurer's aggregate loss is
\begin{equation*}
S=X_{1}+\cdot \cdot \cdot +X_{N}=\sum_{i=1}^{N}X_{i}.
\end{equation*}
\smallskip
\item This is called the \alert{Collective Risk Model}.
\smallskip
\item If $N$, $X_1$, $X_2$, ... are independent and the individual claims $X_i$ are i.i.d., then $S$ has a \textit{compound distribution}.
\smallskip
\item $N$: frequency of claims; $\ \ X$: the severity of claims.
\smallskip
\item Central question is finding the probability distribution of $S$.
\end{itemize}
}

\subsection{Properties}
\frame{\frametitle{Properties of the collective risk model}
\begin{itemize}
\item $X$ is called the individual claim and assume has moments denoted by $\mu_{k}=\text{E}(X^k)$.
\smallskip
\item Mean of $S$: $\text{E}(S) = \text{E}(X) \text{E}(N) = \mu_{1}\text{E}(N)$
\smallskip
\item Variance of $S$: $\text{Var}(S) = \text{E}(N) \text{Var}(X) + \text{Var}(N) \mu_1^2 $
%\smallskip
%\item MGF of $S$: $M_{S}(t) = P_{N}[\log M_{X}(t)]$ where $P_N(\cdot)$ is the probability generating function of $N$. 
\smallskip
\item CDF of $S$: $\text{Pr}(S\leq s) = \sum_{n=0}^{\infty} \text{Pr}(S\leq s|N=n) \text{Pr}(N=n)$
\end{itemize}
}

\subsection{Illustrative example}
\frame{\frametitle{Illustrative example 1}
Suppose that the number of claims follows the distribution in the following table:
\begin{equation*}
\begin{tabular}{ccc}
\hline $n$ &  & $\text{Pr}(N=n)$ \\ \hline\hline
1 &  & 0.35 \\
2 &  & 0.45 \\
3 &  & 0.20 \\ \hline
\end{tabular}
\end{equation*}
When there is a claim, the amount lost has an equal chance of being 100 or 300. Let $S$ be the aggregate loss random variable for total losses. Find the probability that the total claims is less than 450.

\vspace{1 cm}

Find the probability mass function of $S$, i.e. $Pr(S=s)$ for all possible values of $S$. 
}

\subsection{Illustrative example}
\frame{\frametitle{Illustrative example 2}
Let $S = \sum_{i=1}^N X_i$ be a aggregate loss random variable where the number of claims, $N$, is a negative binomial random variable with $\beta = 4$ and $r = 2$ and the severity of each claim is a Lognormal random variable with $\mu = 4$ and $\sigma = 2$. What is the mean and variance of $S$? 

\vspace{1 cm}

%Repeat this using $N$ being a zero-modified Negative Binomial with $p_0^M = 0.6$, $\beta = 4$ and $r = 2$.
}

\subsection{Poisson number of claims}
\frame{\frametitle{Poisson number of claims}
\begin{itemize}
\item If $N \sim$ Poisson$(\lambda)$, so that $\lambda$ is the average number of claims, then the resulting distribution of $S$ is called a \alert{Compound Poisson}.
\smallskip
\smallskip
\item It can then be shown that:
\smallskip
\begin{itemize}
\item Mean of $S$: $\text{E}(S) =\lambda \text{E}(X) = \lambda \mu_{1}$
\smallskip
\item Variance of $S$: $\text{Var}(S) = \lambda \text{E}(X^2) = \lambda \mu_{2}$
\smallskip
\end{itemize}
\end{itemize}
}

\subsection{Illustrative example}
\frame{\frametitle{Illustrative example 3}
Suppose $S$ has a compound Poisson distribution with $\lambda = 0.8$ and individual claim amount distribution
\begin{equation*}
\begin{tabular}{ccc}
\hline $x$ &  & $\text{Pr}(X=x)$ \\ \hline\hline
1 &  & 0.250 \\
2 &  & 0.375 \\
3 &  & 0.375 \\ \hline
\end{tabular}
\end{equation*}
\medskip
What is $E(S)$ and $Var(S)$? 
}



%
%\subsection{Exponential/Geometric}
%\frame{\frametitle{Example - Exponential/Geometric}
%\begin{itemize}
%\item Suppose $X_i \sim $Exp$(1) $ and $N \sim $Geometric$(p)$.
%\smallskip
%\item MGF of $N$: $M_{N}(t) = \dfrac{p}{1-qe^{t}}$; \ \ MGF of $X$: $M_{X}(t) = \dfrac{1}{1-t}$
%\smallskip
%\begin{itemize}
%\item Mean of $S$: $\text{E}(S) = q/p$
%\smallskip
%\item Variance of $S$: $\text{Var}(S) = q/p + q/p^{2}=(q/p)(1+1/p)$
%\smallskip
%\item MGF of $S$: $M_{S}(t) = \dfrac{p}{1-q M_{X}(t)} = \dfrac{p}{1-q/(1-t)} = p+q\dfrac{p}{p-t}$
%\end{itemize}
%\smallskip
%\item Observe that the mgf of $S$ can be written as a weighted average: $ p \times$ mgf of r.v. $0+q\times $ mgf of Exp$(p)$ r.v.
%\smallskip
%\item Thus, $F_{S}(s) = p + q(1-e^{-ps}) = 1- qe^{-ps}$ for $s>0$.
%\end{itemize}
%}
%





%\subsection{Panjer's recursion formula}
%\frame{\frametitle{Panjer's recursion formula}
%\begin{itemize}
%\item Let aggregate claims $S$ have a compound distribution with integer-valued non-negative claims with pdf $p(x)$ for $ x = 0,1,2,\ldots$.
%\smallskip
%\item Let the probability of $n$ claims satisfies the recursion relation $p_k= (a+\frac{b}{n}) p_{k-1}$ for $k=1,2,\ldots$ for some real $a$ and $b$. Recall this is the $(a,b,1)$ class of distribution.
%\smallskip
%\item Then, for the probability of total claims $s$, we have
%\begin{equation*}
%f_{S}(s) = \frac{1}{1-ap(0)} \sum_{h=1}^{s}\left(a + \frac{bh}{s}\right) p(h) f_{S}(s-h).
%\end{equation*}
%
%\item For $s=0$, we have $f_{S}(0) = \left\{
%\begin{array}{ll}
%\text{Pr}(N=0), & \text{if } p(0) =0 \\
%M_{N}\left[\log p(0) \right], & \text{if } p(0)>0
%\end{array}
%\right. $.
%\end{itemize}
%}
%
%\subsection{The case of Compound Poisson}
%\frame{\frametitle{Panjer's recursion for Compound Poisson}
%\begin{itemize}
%\item This is the case where the number of claims is Poisson.
%\smallskip
%\item Starting value:
%\begin{equation*}
%f_{S}(0) = \left\{
%\begin{array}{ll}
%\text{Pr}(N=0), & \text{if } p(0)=0 \\
%M_{N}\left[\log p(0) \right], & \text{if } p(0)>0
%\end{array}
%\right. \text{.}
%\end{equation*}
%
%\item With Poisson$(\lambda)$:
%\begin{equation*}
%f_{S}(s) = \frac{1}{s} \sum_{h=1}^{s}\lambda hp(h) f_{S}(s-h).
%\end{equation*}
%\end{itemize}
%}
%
%\subsection{Illustrative example}
%\frame{\frametitle{Back to illustrative example 2}
%Same as previous example, but now we solve using Panjer's recursion. \\
%\smallskip
%Effectively, the recursion formula boils down to
%\begin{equation*}
%f_{S}(s) = \frac{1}{s} [0.2 f_{S}(s-1) + 0.6 f_{S}(s-2) + 0.9 f_{S}(s-3)].
%\end{equation*}
%[Why??]
%\smallskip
%Initial value is: $f_{S}(0) = \text{Pr}(N=0) = e^{-0.8} = 0.44933$. \\
%\smallskip
%Successive values satisfy:
%\begin{eqnarray*}
%f_{S}(1) &=& 0.2 f_{S}(0) = 0.2 e^{-0.8} = 0.089866 \\
%f_{S}(2) &=&\frac{1}{2}[0.2 f_{S}(1) + 0.6 f_{S}(0)] = 0.32 e^{-0.8} = 0.14379 \\
%f_{S}(3) &=&\frac{1}{3}[0.2 f_{S}(2) + 0.6 f_{S}(1) + 0.9 f_{S}(0)] = 0.3613e^{-0.8} = 0.16236
%\end{eqnarray*}
%and $f_{S}(4) = 0.0499$, $f_{S}(5) = 0.04736$, and $f_{S}(6) = 0.03092$. [calculated by hand - verify!]
%}

%
%
%\subsection{Closed under convolution}
%\frame{\frametitle{Compound Poisson is closed under convolution}
%\begin{itemize}
%\item Theorem 9.7 of book.
%\smallskip
%\item If $S_1,S_2,\ldots,S_m$ are independent compound Poisson random variables with Poisson parameters $\lambda_i$ and claim distributions (CDF) $F_{i}$, for $i=1,2,\ldots,m$, then
%\begin{equation*}
%S = S_1 + S_2+ \cdots + S_m
%\end{equation*}%
%also has a compound Poisson distribution with parameter $\lambda = \lambda_1+\lambda_2+\cdots +\lambda_m$ and individual claim (severity) distribution
%\begin{equation*}
%F(x) =\sum_{i=1}^{m}\frac{\lambda_i}{\lambda}F_{i}(x).
%\end{equation*}
%\item You add the number of claim parameters, and the individual claim distribution is a weighted sum.
%\end{itemize}
%}
%
%\subsection{Illustrative example}
%\frame{\frametitle{Illustrative example 3}
%You are given $S=S_1+S_2$, where $S_{1}$ and $S_{2}$ are independent and have compound Poisson distributions with $\lambda_1=3$ and $\lambda_2=2$ and individual claim amount distributions:
%\begin{equation*}
%\begin{tabular}{ccccc}
%\hline
%$x$ &  & $p_{1}(x)$ &  & $p_{2}(x)$ \\ \hline
%$1$ &  & $0.25$ &  & $0.10$ \\
%$2$ &  & $0.75$ &  & $0.40$ \\
%$3$ &  & $0.00$ &  & $0.40$ \\
%$4$ &  & $0.00$ &  & $0.10$ \\ \hline
%\end{tabular}
%\end{equation*}
%\medskip
%Determine the mean and variance of the individual claim amount for $S$.
%}

\subsection{Approximating the compound distribution}
\frame{\frametitle{Use CLT to approximate the compound distribution}
\begin{itemize}
\item If the average number of claims is large enough, we may use the Normal approximation to estimate the distribution of $S$.
\smallskip
\item All you need are the mean and variance of the aggregate loss
\end{itemize}
}

\end{document}
